{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['far cours studi associ rule mine learn frequent itemset', 'past coupl week start learn text mine', 'data mine text mine fun topic', 'holiday fun wait till next holiday']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy import sparse\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "Doc1 = \"So far in this course, we have studied association rule mining and we learned about frequent itemsets\"\n",
    "Doc2 = \"During the past couple of weeks, we started learning about Text Mining\"\n",
    "Doc3 = \"Data Mining and Text Mining are fun topics!\"\n",
    "Doc4 = \"Holidays are fun! I can’t wait till my next holiday…\"\n",
    "Docs = [Doc1,Doc2,Doc3,Doc4]\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "def preprocessCorpus(corpus):\n",
    "    Do1, Do2, Dox = [], [], []\n",
    "\n",
    "    for Doc in Docs:\n",
    "        Do1.append(Doc.casefold())\n",
    "        \n",
    "    for Doc in Do1:\n",
    "        curr = \"\"\n",
    "        for word in  re.split(\"\\W+\",Doc):\n",
    "            if word not in stopwords: \n",
    "                curr = curr + word +\" \"\n",
    "        curr = curr.strip()\n",
    "        Do2.append(curr)\n",
    "\n",
    "    for Doc in  Do2:\n",
    "        curr = \"\"\n",
    "        for word in Doc.split():  \n",
    "            curr = curr + PorterStemmer().stem(word) +\" \"\n",
    "        curr = curr.strip()\n",
    "        Dox.append(curr)\n",
    "    return Dox\n",
    "\n",
    "Dox = preprocessCorpus(Docs)\n",
    "print(Dox)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "V = vectorizer.fit_transform(Dox).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.60205999 0.         0.60205999 0.         0.60205999 0.60205999\n",
      "  0.         0.         0.60205999 0.30103    0.20068666 0.\n",
      "  0.         0.60205999 0.         0.60205999 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.60205999 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.30103    0.20068666 0.\n",
      "  0.60205999 0.         0.60205999 0.         0.30103    0.\n",
      "  0.         0.         0.60205999]\n",
      " [0.         0.         0.         0.60205999 0.         0.\n",
      "  0.30103    0.         0.         0.         0.40137333 0.\n",
      "  0.         0.         0.         0.         0.30103    0.\n",
      "  0.60205999 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.30103    1.20411998 0.         0.         0.         0.60205999\n",
      "  0.         0.         0.         0.         0.         0.60205999\n",
      "  0.         0.60205999 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def getTF_IDF(corpus):\n",
    "    TF, IDF, TF_IDF, N = [], [], [], []\n",
    "    for i in range(4):\n",
    "        tf = V[i] #/ len(Dox[i].split()) || 1 + log(V[i] / len(Dox[i].split()))\n",
    "        TF.append(tf)\n",
    "\n",
    "    index = 0\n",
    "    Sum = [0]*21\n",
    "    for i in V.T:    \n",
    "        if 2 not in i:\n",
    "            Sum[index] = sum(i)\n",
    "        elif 2 in i:\n",
    "            Z = sum(i)\n",
    "            Sum[index] = Z - 1\n",
    "        index = index+1\n",
    "\n",
    "    for i in range(len(Sum)):\n",
    "        idf = math.log10(len(Dox))/Sum[i]\n",
    "        IDF.append(idf)\n",
    "\n",
    "    for i in range(len(V)):\n",
    "        TF_idf = TF[i] * IDF\n",
    "        TF_IDF.append(TF_idf)\n",
    "        \n",
    "    #for i in range(4):\n",
    "    #    normalized = (TF_IDF[i]-min(TF_IDF[i]))/(max(TF_IDF[i])-min(TF_IDF[i]))\n",
    "    #    N.append(normalized)\n",
    "    Sp = sparse.csr_matrix(TF_IDF)#to.array()\n",
    "    return Sp\n",
    "\n",
    "IDF_vec = getTF_IDF(Dox).toarray()\n",
    "print(IDF_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sim1(v1, v2):\n",
    "    result = np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.48076197]), array([0.27441065]), array([0.08687445]), array([0.])]\n"
     ]
    }
   ],
   "source": [
    "Q = ['Text mining'][0].split()\n",
    "X = []\n",
    "curr = \"\"\n",
    "for word in Q:  \n",
    "    curr = curr + PorterStemmer().stem(word) +\" \"\n",
    "curr = curr.strip()\n",
    "X.append(curr)\n",
    "v1 = vectorizer.transform(X).toarray()\n",
    "index = 0\n",
    "Sum = [0]*21\n",
    "for i in V.T:    \n",
    "    if 2 not in i:\n",
    "        Sum[index] = sum(i)\n",
    "    elif 2 in i:\n",
    "        Z = sum(i)\n",
    "        Sum[index] = Z - 1\n",
    "    index = index+1\n",
    "IDFv1 = []\n",
    "for i in v1:\n",
    "    index = 0\n",
    "    for x in i:\n",
    "        x = x * math.log10(len(Dox))/Sum[index]\n",
    "        IDFv1.append(x)\n",
    "    index += 1\n",
    "v1 = np.array(IDFv1).reshape(-1,1).T\n",
    "\n",
    "Cos = []\n",
    "for Doc in IDF_vec:\n",
    "    Cos.append(Sim1(v1,Doc))\n",
    "Cos.sort(reverse=True)\n",
    "print(Cos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
